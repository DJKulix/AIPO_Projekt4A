{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Wprowadzenie do uczenia kontrastowego w analizie obrazów\n",
    "\n",
    "Notebook omawia pojęcie uczenia kontrastowego (contrastive learning)\n",
    "w kontekście analizy i przetwarzania obrazów. Notebook zakłada pewną wiedzę teoerytczną na temat uczenia maszynowego oraz obsługę pakietów związanych z analizą obrazów.\n",
    "\n",
    "## Cele zajęć:\n",
    "- zrozumienie idei par pozytywnych i negatywnych oraz roli augmentacji,\n",
    "- implementacja pętli uczącej kontrastywnie (SimCLR)\n",
    "- wizualizacja reprezentacji (t-SNE)\n",
    "- przeprowadzenie sondowania liniowego\n",
    "\n"
   ],
   "id": "6cb04bbe6fa53323"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Przygotowanie środowiska\n",
    "\n",
    "Dla lepszego działania sieci zalecena jest użycie GPU wspierającego CUDA lub użycie Google Colab i ustawienie odpowiedniego GPU w menu _Runtime_\n",
    "\n",
    "### Instalacja pakietów\n"
   ],
   "id": "c9205b9c7fad3997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install matplotlib scikit-learn\n",
    "!pip install tqdm\n"
   ],
   "id": "3a09bc7c28deeb7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import pakietów",
   "id": "cd7d6ce3f1bfb477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n"
   ],
   "id": "a31db62ff0faa2e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ustawienia programu",
   "id": "8027fbe66b747190"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Ograniczenie epok dla przyspieszenia działania programu\n",
    "FAST = True if device == \"cpu\" else False\n",
    "\n",
    "BATCH_SIZE = 128 if device == \"cuda\" else 64\n",
    "EPOCHS_PRETRAIN = 1 if FAST else 3\n",
    "EPOCHS_LINEAR = 3 if FAST else 10\n",
    "NUM_WORKERS = 2\n",
    "epochs = EPOCHS_PRETRAIN\n"
   ],
   "id": "7a996c82f8444a70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wprowadzenie teoretyczne: contrastive learning\n",
    "\n",
    "Uczenie kontrastywne (contrastive learning) to podejście samonadzorowane, w którym model uczy się reprezentacji tak, aby \"zbliżać\" do siebie reprezentacje par podobnych przykładów (positive pairs) i \"oddalać\" reprezentacje przykładów niepodobnych (negative pairs). Zamiast etykiet klas, sygnałem uczącym jest relacja podobieństwa między widokami danych, np. dwie augmentacje tego samego obrazu samochodu będą bliżej siebie w reprezentacji niż augmentacja samochodu i augmentacja psa.\n",
    "\n",
    "- Dlaczego używamy contrastive learning?\n",
    "  - Brak lub niepełne etykiety w zbiorze danych.\n",
    "  - Model uczy się cech stabilnych względem zakłóceń i transformacji.\n",
    "  - Transfer learning poprawia wyniki w późniejszych zadaniach z małą liczbą etykiet (fine‑tuning, linear probe).\n",
    "\n",
    "- Przykład działania SimCLR\n",
    "  - Dla każdego obrazu tworzymy dwie niezależne, losowe augmentacje – parę pozytywną (positive).\n",
    "  - Obrazy pochodzące od innych przykładów tworzą parę negatywną (negative).\n",
    "  - Encoder jest uczony tak, aby maksymalizować podobieństwo reprezentacji par pozytywnych i minimalizować podobieństwo par negatywnych.\n",
    "\n",
    "- Rola augmentacji danych\n",
    "  - Augmentacje powinny zmieniać powierzchowne aspekty obrazu (kolor, kadrowanie, szum), ale zachowywać semantykę obiektu, dzięki temu model traktuje różne augmentacje tego samego obiektu jako pary pozytywne, mimo zmian koloru, kadrowania czy oświetlenia.\n",
    "  - Zbyt słabe augmentacje będą dawać słabe wyniki.\n",
    "  - Augmentacje mogą być zbyt agresywne. Model może klasyfikować podobne obrazy jako pary negatywne.\n",
    "\n",
    "- Contrastive loss (NT‑Xent)\n",
    "  - Dla pary pozytywnej (i, j) maksymalizujemy podobieństwo cosinusowe sim(i, j), a dla wszystkich k ≠ i, j w paczce minimalizujemy sim(i, k) i sim(j, k).\n",
    "  - Temperatura τ \"wyostrza\" rozkład softmax: mniejsza τ zwiększa kontrast między podobieństwami.\n",
    "\n",
    "- Zastosowania\n",
    "  - Wizja: klasyfikacja, detekcja, segmentacja (pre‑trening na obrazach bez etykiet).\n",
    "  - NLP, audio, grafy – idea podobna, inny rodzaj augmentacji/widoków.\n",
    "\n",
    "W notebooku zaimplementujemy wariant SimCLR na zbiorze CIFAR‑10 wraz z wizualizacją i sondowaniem liniowym.\n"
   ],
   "id": "18dce4213ebec17d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zdefiniowanie transformacji\n",
    "Uzupełnij definicję transformacji danych, tworząc sekwencję augmentacji wykorzystywanych w metodzie SimCLR. W tym celu użyj klasy transforms.Compose i dodaj następujące\n",
    "transformacje w odpowiedniej kolejności:\n",
    "- losowe przycięcie i przeskalowanie obrazu do rozmiaru 32×32,\n",
    "- losowe odbicie poziome obrazu,\n",
    "- losową zmianę jasności, kontrastu, nasycenia i odcienia przy użyciu ColorJitter, stosowaną z prawdopodobieństwem 0.8m,\n",
    "- konwersję obrazu do skali szarości z prawdopodobieństwem 0.2,\n",
    "- konwersję obrazu do tensora"
   ],
   "id": "e0936a78061b62c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "  # uzupelnij kod\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
   ],
   "id": "ffa45b625c7262bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Podgląd augmentacji\n",
    "Aby lepiej zrozumieć rolę augmentacji, wyświetlmy kilka widoków tego samego obrazu. Zobacz, które transformacje mogą być korzystne, a które mogą za bardzo zniekształcać dane. Z bloku powyżej usuń te, które twoim zdaniem mogą negatywnie wpłynąć na jakość modelu.\n"
   ],
   "id": "edddb58f33c17578"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "\n",
    "def show_augmented_sample(dataset, idx=0, n_views=6):\n",
    "    x, _ = dataset[idx]\n",
    "    # oryginalny obraz (bez augmentacji) do porównania\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    base = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "    x0, _ = base[idx]\n",
    "    imgs = [x0]\n",
    "    for _ in range(n_views):\n",
    "        xi, _ = dataset[idx]\n",
    "        imgs.append(xi)\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow=n_views+1, padding=2)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.title('Oryginał (pierwszy obraz) + różne widoki augmentacji')\n",
    "    plt.show()\n",
    "\n",
    "print('Podgląd augmentacji:')\n",
    "show_augmented_sample(train_dataset, idx=5, n_views=6)\n",
    "\n",
    "# Loader ewaluacyjny (test) do t‑SNE i linear probe\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_set = datasets.CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
    "if FAST:\n",
    "    test_set = Subset(test_set, list(range(2000)))\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=NUM_WORKERS)"
   ],
   "id": "88dc9e1cee7f5a66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Definicja modelu\n",
    "Uzupełnij definicję klasy SimCLRModel, aby uzyskać sieć z następującymi parametrami:\n",
    "- warstwa wejściowa: 512 wejść i 256 wyjść,\n",
    "- funkcją aktywacji ReLU między pierwszą i drugą warstwą\n",
    "- warstwę wyjściową: 256 wejść, wyjście oparte na zmiennej _projection_dim_ z domyślną wartoscią równą 128"
   ],
   "id": "fba33642e7d1e0e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimCLRModel(nn.Module):\n",
    "    def __init__(self, base_encoder, projection_dim=128):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "model = SimCLRModel(models.resnet18(weights=models.ResNet18_Weights.DEFAULT)).to(device)"
   ],
   "id": "f6affdfeef627d8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### MLP i normalizacja\n",
    "\"Projection head\" (MLP) rzutuje cechy encodera `h` do nowej przestrzeni reprezentacji `z`, w której obliczane jest podobieństwo oraz funkcja straty kontrastywnej.\n",
    "W praktyce:\n",
    "- Używa się niewielkiej sieci MLP z funkcją aktywacji ReLU, która daje lepsze wyniki niż pojedyncza warstwa liniowa.-\n",
    "- Często stosuje się normalizację L2 wektorów `z`, co powoduje, że mają one długość równą 1. Dzięki temu podobieństwo cosinusowe zależy wyłącznie od kąta między wektorami, a nie od ich skali.\n",
    "- Projection head jest używany wyłącznie podczas uczenia kontrastywnego. W ewaluacji liniowej (linear probe) wykorzystuje się bezpośrednio cechy encodera h, bez warstwy projekcyjnej.).\n",
    "\n",
    "\n",
    "Uzupełnij poniższy kod, aby wyświetlić podstawowe statystyki modelu oraz zmierzyć czas wykonania pojedynczego przejścia w przód (forward pass).\n"
   ],
   "id": "1ef4dea9f892dbad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Statystyki modelu i szybki benchmark\n",
    "\n",
    "def count_parameters(m: nn.Module):\n",
    "    # TODO: oblicz całkowitą liczbę parametrów modelu\n",
    "    total = ...\n",
    "\n",
    "    # TODO: oblicz liczbę parametrów trenowalnych\n",
    "    trainable = ...\n",
    "\n",
    "    return total, trainable\n",
    "\n",
    "total, trainable = count_parameters(model)\n",
    "print(f\"Parametry (łącznie): {total/1e6:.2f} M | Trenowalne: {trainable/1e6:.2f} M\")\n",
    "print(model.encoder.__class__.__name__, \"→ projection_dim:\", 128)\n",
    "\n",
    "bs = 128 if device == 'cuda' else 64\n",
    "# TODO: utwórz losowy tensor o rozmiarze (bs, 3, 32, 32) na odpowiednim device\n",
    "x_dummy = ...\n",
    "\n",
    "# warmup\n",
    "_ = model(x_dummy)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "start = time.time()\n",
    "_ = model(x_dummy)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "elapsed = (time.time() - start) * 1000\n",
    "print(f\"Czas forward dla batch={bs}: {elapsed:.1f} ms\")"
   ],
   "id": "c12df2e92b88213c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Definicja funkcji contrastive loss (NT‑Xent)\n",
    "\n",
    "NT-Xent (Normalized Temperature-scaled Cross Entropy) to funkcja straty kontrastywnej, która porównuje każdą reprezentację z jej pozytywnym odpowiednikiem w obrębie tej samej paczki, traktując wszystkie pozostałe reprezentacje jako przykłady negatywne.\n",
    "\n",
    "Intuicyjnie celem jest maksymalizacja podobieństwa cosinusowego między parami pozytywnymi oraz minimalizacja podobieństwa między parami negatywnymi.\n",
    "Temperatura τ kontroluje „ostrość” rozkładu softmax — mniejsze wartości τ powodują większe rozróżnienie między podobieństwami, wzmacniając wpływ najbardziej podobnych i najbardziej niepodobnych przykładów.\n",
    "\n",
    "W praktyce wektory projekcji z są normalizowane do normy L2, co powoduje, że mają długość równą 1. Dzięki temu iloczyn skalarny między wektorami odpowiada podobieństwu\n",
    "cosinusowemu, które jest następnie wykorzystywane w funkcji straty.\n",
    "\n",
    "Uzupełnij poniższą klasę implementującą funkcję straty kontrastywnej:"
   ],
   "id": "4b47d8e570d70b10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "\n",
    "        # TODO: połącz z_i i z_j w jeden tensor o rozmiarze (2*batch_size, dim)\n",
    "        z = ...\n",
    "\n",
    "        # TODO: oblicz macierz podobieństwa i podziel przez temperaturę\n",
    "        sim_matrix = ...\n",
    "\n",
    "        # TODO: usuń podobieństwo elementów z samymi sobą (diagonalę)\n",
    "        sim_matrix = ...\n",
    "\n",
    "        # TODO: utwórz etykiety wskazujące pozytywne pary\n",
    "        labels = ...\n",
    "\n",
    "        # TODO: oblicz contrastive loss przy użyciu CrossEntropyLoss\n",
    "        loss = ...\n",
    "\n",
    "        return loss\n",
    "\n",
    "contrastive_loss = ContrastiveLoss()"
   ],
   "id": "c73e45808a4300a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Trening modelu\n",
    "\n"
   ],
   "id": "645563c92305469d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "hist_loss = []\n",
    "hist_time = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\")\n",
    "    for batch_idx, (images, _) in enumerate(pbar, start=1):\n",
    "        images = images.to(device)\n",
    "        # pozytywna para: dwa niezależne widoki tego samego obrazu\n",
    "        images = torch.cat([images, images], dim=0)\n",
    "        z_i, z_j = model(images).chunk(2, dim=0)\n",
    "\n",
    "        loss = contrastive_loss(z_i, z_j)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(avg_loss=f\"{running_loss/batch_idx:.4f}\")\n",
    "\n",
    "    avg_ep = running_loss/len(train_loader)\n",
    "    hist_loss.append(avg_ep)\n",
    "    hist_time.append(time.time() - t0)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] done | avg_loss: {avg_ep:.4f} | time: {hist_time[-1]:.1f}s\")\n"
   ],
   "id": "7e1c4758da98acc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres straty treningowej i statystyk czasu",
   "id": "608e385b7808006b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_loss, marker='o')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('NT-Xent loss (avg/epoka)')\n",
    "plt.title('Krzywa uczenia (pre‑training)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Średni czas/epoka: {np.mean(hist_time):.1f}s ± {np.std(hist_time):.1f}s (n={len(hist_time)})\")"
   ],
   "id": "30760c761a06500a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wizualizacja embeddingów (t‑SNE)\n",
    "\n",
    "Porównajmy rozkład reprezentacji przed i po pre‑trainingu.\n"
   ],
   "id": "7a85951b3652a0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def extract_embeddings(model, loader, max_batches=20):\n",
    "    model.eval()\n",
    "    embs = []\n",
    "    labels = []\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        h = model.encoder(x)\n",
    "        embs.append(h.cpu().numpy())\n",
    "        labels.append(y.numpy())\n",
    "        if i+1 >= max_batches:\n",
    "            break\n",
    "    embs = np.concatenate(embs, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return embs, labels\n",
    "\n",
    "print(\"Ekstrakcja embeddingów do t‑SNE\")\n",
    "embs, labs = extract_embeddings(model, test_loader, max_batches=30 if not FAST else 10)\n",
    "\n",
    "print(\"t‑SNE\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='pca', random_state=SEED)\n",
    "XY = tsne.fit_transform(embs)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "scatter = plt.scatter(XY[:,0], XY[:,1], c=labs, s=6, cmap='tab10', alpha=0.8)\n",
    "plt.legend(*scatter.legend_elements(), title=\"CIFAR10\")\n",
    "plt.title(\"t‑SNE reprezentacji po pre‑trainingu (kolor=klasa)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "3392e4ddb0feab30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ewaluacja liniowa\n",
    "\n",
    "Zamrażamy encoder (jego wagi nie są już aktualizowane) i uczymy niewielki klasyfikator liniowy na podstawie generowanych przez niego cech `h`.\n",
    "Jest to szybka metoda oceny jakości reprezentacji wyuczonych w procesie uczenia samonadzorowanego.\n"
   ],
   "id": "9f1236383a75db61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, in_dim: int, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_features(encoder, loader):\n",
    "    encoder.eval()\n",
    "    X, Y = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        h = encoder(x)\n",
    "        X.append(h.cpu())\n",
    "        Y.append(y)\n",
    "    return torch.cat(X), torch.cat(Y)\n",
    "\n",
    "# Zamrożenie encodera\n",
    "for p in model.encoder.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "# Dane do linear probe (cały test_set jako eval; do treningu weźmy część train_base z lekką transformacją)\n",
    "train_lin = datasets.CIFAR10(root=\"./data\", train=True, download=False, transform=test_transform)\n",
    "if FAST:\n",
    "    train_lin = Subset(train_lin, list(range(6000)))\n",
    "\n",
    "train_lin_loader = DataLoader(train_lin, batch_size=256, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "Xtr, Ytr = infer_features(model.encoder, train_lin_loader)\n",
    "Xte, Yte = infer_features(model.encoder, test_loader)\n",
    "\n",
    "probe = LinearProbe(in_dim=Xtr.size(1), num_classes=10).to(device)\n",
    "opt = torch.optim.Adam(probe.parameters(), lr=5e-3)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_probe(probe, Xtr, Ytr, Xte, Yte, epochs=EPOCHS_LINEAR):\n",
    "    probe.train()\n",
    "    dataset = torch.utils.data.TensorDataset(Xtr, Ytr)\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    for ep in range(1, epochs+1):\n",
    "        loss_ep = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = probe(xb)\n",
    "            loss = ce(logits, yb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_ep += loss.item()\n",
    "        with torch.no_grad():\n",
    "            probe.eval()\n",
    "            te_logits = probe(Xte.to(device))\n",
    "            pred = te_logits.argmax(dim=1).cpu()\n",
    "            acc = (pred == Yte).float().mean().item()\n",
    "            probe.train()\n",
    "        print(f\"Ep {ep}/{epochs} | loss={loss_ep/len(loader):.4f} | test acc={acc*100:.2f}%\")\n",
    "\n",
    "print(\"Trening linear probe...\")\n",
    "train_probe(probe, Xtr, Ytr, Xte, Yte, epochs=EPOCHS_LINEAR)\n"
   ],
   "id": "40dd899028db3c81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zadania do wykonania\n",
    "\n",
    "- Jaki wpływ będzie miała zmiana temperatury `tau` w NT-Xent na _loss_ i _linear probe_? Wypróbuj wartości 0.07 i 0.5\n",
    "- Wypróbuj 2-3 różne zestawy augmentacji i zapisz wyniki (np. usuń/zmień GaussianBlur, ColorJitter, scale w RandomResizedCrop).\n",
    "- Przeanalizuj wpływ rozmiaru batcha na wyniki — większy batch zapewnia więcej przykładów negatywnych, ale wydłuża czas obliczeń.\n",
    "- Wydłuż pre‑training do 5–10 epok (na GPU) i przetestuj program.\n",
    "- Przetestuj model na innym zbiorze danych, np. STL10 z wykorzystaniem części nieetykietowanej."
   ],
   "id": "9e1c22901a816b23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
